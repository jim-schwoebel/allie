## Training scripts 

Quickly train according to the default_training_script using model.py.

![](https://github.com/jim-schwoebel/Allie/blob/master/training/helpers/train.gif)

## Getting started

All you need to do to get started is go to this repository and run upgrade.py followed by model.py:

```
cd allie/training
python3 upgrade.py
python3 model.py 
```

You then will be asked a few questions regarding the training process (in terms of data type, number of classes, and the name of the model). Note that --> indicates typed responses. 

```
what problem are you solving? (1-audio, 2-text, 3-image, 4-video, 5-csv)
--> 1

 OK cool, we got you modeling audio files 

how many classes would you like to model? (2 available) 
--> 2
these are the available classes: 
['one', 'two']
what is class #1 
--> one
what is class #2 
--> two
what is the 1-word common name for the problem you are working on? (e.g. gender for male/female classification) 
--> test
is this a classification (c) or regression (r) problem? 
--> c
```

After this, the model will be trained and placed in the models/[sampletype_models] directory. For example, if you trained an audio model with TPOT, the model will be placed in the allie/models/audio_models/ directory. 

For automated training, you can alternatively pass through sys.argv[] inputs as follows:

```
python3 model.py audio 2 c male female
```
Where:
- audio = audio file type 
- 2 = 2 classes 
- c = classification (r for regression)
- male = first class
- female = second class [via N number of classes]

Goal is to make an output folder like this:
```
‚îî‚îÄ‚îÄ commonname_tpot
    ‚îú‚îÄ‚îÄ classes.png
    ‚îú‚îÄ‚îÄ clustering
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ isomap.png
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ lle.png
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ mds.png
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ modified.png
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ pca.png
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ spectral.png
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ tsne.png
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ umap.png
    ‚îú‚îÄ‚îÄ data
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ m_f_all.csv
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ m_f_all_transformed.csv
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ m_f_test.csv
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ m_f_test_transformed.csv
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ m_f_train.csv
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ m_f_train_transformed.csv
    ‚îú‚îÄ‚îÄ feature_ranking
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ feature_importance.png
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ feature_plots
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 0_onset_length.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 100_mfcc_4_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 101_mfcc_4_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 102_mfcc_5_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 103_mfcc_5_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 104_mfcc_5_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 105_mfcc_5_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 106_mfcc_5_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 107_mfcc_6_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 108_mfcc_6_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 109_mfcc_6_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 10_onset_strength_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 110_mfcc_6_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 111_mfcc_6_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 112_mfcc_7_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 113_mfcc_7_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 114_mfcc_7_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 115_mfcc_7_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 116_mfcc_7_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 117_mfcc_8_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 118_mfcc_8_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 119_mfcc_8_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 11_onset_strength_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 120_mfcc_8_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 121_mfcc_8_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 122_mfcc_9_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 123_mfcc_9_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 124_mfcc_9_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 125_mfcc_9_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 126_mfcc_9_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 127_mfcc_10_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 128_mfcc_10_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 129_mfcc_10_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 12_rhythm_0_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 130_mfcc_10_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 131_mfcc_10_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 132_mfcc_11_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 133_mfcc_11_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 134_mfcc_11_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 135_mfcc_11_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 136_mfcc_11_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 137_mfcc_12_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 138_mfcc_12_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 139_mfcc_12_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 13_rhythm_0_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 140_mfcc_12_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 141_mfcc_12_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 142_poly_0_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 143_poly_0_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 144_poly_0_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 145_poly_0_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 146_poly_0_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 147_poly_1_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 148_poly_1_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 149_poly_1_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 14_rhythm_0_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 150_poly_1_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 151_poly_1_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 152_spectral_centroid_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 153_spectral_centroid_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 154_spectral_centroid_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 155_spectral_centroid_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 156_spectral_centroid_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 157_spectral_bandwidth_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 158_spectral_bandwidth_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 159_spectral_bandwidth_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 15_rhythm_0_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 160_spectral_bandwidth_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 161_spectral_bandwidth_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 162_spectral_contrast_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 163_spectral_contrast_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 164_spectral_contrast_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 165_spectral_contrast_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 166_spectral_contrast_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 167_spectral_flatness_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 168_spectral_flatness_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 169_spectral_flatness_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 16_rhythm_0_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 170_spectral_flatness_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 171_spectral_flatness_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 172_spectral_rolloff_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 173_spectral_rolloff_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 174_spectral_rolloff_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 175_spectral_rolloff_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 176_spectral_rolloff_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 177_zero_crossings_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 178_zero_crossings_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 179_zero_crossings_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 17_rhythm_1_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 180_zero_crossings_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 181_zero_crossings_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 182_RMSE_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 183_RMSE_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 184_RMSE_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 185_RMSE_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 186_RMSE_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 18_rhythm_1_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 19_rhythm_1_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 1_onset_detect_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 20_rhythm_1_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 21_rhythm_1_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 22_rhythm_2_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 23_rhythm_2_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 24_rhythm_2_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 25_rhythm_2_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 26_rhythm_2_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 27_rhythm_3_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 28_rhythm_3_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 29_rhythm_3_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 2_onset_detect_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 30_rhythm_3_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 31_rhythm_3_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 32_rhythm_4_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 33_rhythm_4_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 34_rhythm_4_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 35_rhythm_4_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 36_rhythm_4_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 37_rhythm_5_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 38_rhythm_5_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 39_rhythm_5_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 3_onset_detect_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 40_rhythm_5_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 41_rhythm_5_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 42_rhythm_6_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 43_rhythm_6_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 44_rhythm_6_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 45_rhythm_6_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 46_rhythm_6_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 47_rhythm_7_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 48_rhythm_7_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 49_rhythm_7_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 4_onset_detect_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 50_rhythm_7_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 51_rhythm_7_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 52_rhythm_8_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 53_rhythm_8_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 54_rhythm_8_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 55_rhythm_8_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 56_rhythm_8_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 57_rhythm_9_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 58_rhythm_9_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 59_rhythm_9_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 5_onset_detect_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 60_rhythm_9_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 61_rhythm_9_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 62_rhythm_10_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 63_rhythm_10_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 64_rhythm_10_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 65_rhythm_10_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 66_rhythm_10_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 67_rhythm_11_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 68_rhythm_11_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 69_rhythm_11_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 6_tempo.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 70_rhythm_11_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 71_rhythm_11_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 72_rhythm_12_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 73_rhythm_12_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 74_rhythm_12_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 75_rhythm_12_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 76_rhythm_12_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 77_mfcc_0_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 78_mfcc_0_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 79_mfcc_0_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 7_onset_strength_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 80_mfcc_0_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 81_mfcc_0_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 82_mfcc_1_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 83_mfcc_1_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 84_mfcc_1_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 85_mfcc_1_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 86_mfcc_1_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 87_mfcc_2_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 88_mfcc_2_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 89_mfcc_2_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 8_onset_strength_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 90_mfcc_2_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 91_mfcc_2_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 92_mfcc_3_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 93_mfcc_3_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 94_mfcc_3_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 95_mfcc_3_minv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 96_mfcc_3_median.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 97_mfcc_4_mean.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 98_mfcc_4_std.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 99_mfcc_4_maxv.png
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ 9_onset_strength_maxv.png
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ heatmap.png
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ heatmap_clean.png
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ lasso.png
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ pearson.png
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ shapiro.png
    ‚îú‚îÄ‚îÄ modeling
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ calibration.png
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ cluster_distance.png
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ elbow.png
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ks.png
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ learning_curve.png
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ logr_percentile_plot.png
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ outliers.png
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ pca_explained_variance.png
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ precision-recall.png
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ prediction_error.png
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ residuals.png
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ roc_curve.png
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ roc_curve_train.png
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ siloutte.png
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ thresholds.png
    ‚îî‚îÄ‚îÄ models
        ‚îú‚îÄ‚îÄ m_f_librosa_features.png
        ‚îú‚îÄ‚îÄ m_f_librosa_features_tpotclassifier.json
        ‚îú‚îÄ‚îÄ m_f_librosa_features_tpotclassifier.pickle
        ‚îú‚îÄ‚îÄ m_f_librosa_features_tpotclassifier.py
        ‚îî‚îÄ‚îÄ m_f_librosa_features_tpotclassifier_transform.pickle
```

Now you're ready to go to load these models and [make predictions](https://github.com/jim-schwoebel/allie/tree/master/models).

## V1 training scripts

There are 21 potential training script settings (customized in the 'settings.json'). Recommended setting is TPOT.

* '[btb](https://github.com/HDI-Project/BTB)' - hyperparameter tuning with various ML algorithms in scikit-learn using genetic algorithms. &#x2611;
* '[devol](https://github.com/joeddav/devol)' - genetic programming keras cnn layers. &#x2611;
* '[gama](https://github.com/PGijsbers/gama)' - An automated machine learning tool based on genetic programming. &#x2611; 
* '[imbalance-learn](https://pypi.org/project/imbalanced-learn/)' - imbalance learn different ML techniques to work on data with different numbers of samples. (could use expanding a bit). &#x2611;
* '[keras](https://keras.io/getting-started/faq/)' - simple MLP network architecture (quick prototype - if works may want to use autoML settings). &#x2611;
* '[ludwig](https://github.com/uber/ludwig)' - deep learning (simple ludwig). - convert every feature to numerical data. &#x2611; 
* '[mlblocks](https://github.com/HDI-Project/MLBlocks)' - most recent framework @ MIT, regression and classification. &#x2611; 
* '[neuraxle](https://github.com/Neuraxio/Neuraxle)' - A sklearn-like Framework for Hyperparameter Tuning and AutoML in Deep Learning projects. &#x2611;
* '[safe](https://github.com/ModelOriented/SAFE)' - black box trainer / helps reduce opacity of ML models while increasing accuracy.&#x2611;

Note some of the deep learning autoML techniques can take days for optimization, and there are compromises in accuracy vs. speed in training.


## V2 architecture model training

* '[alphapy](https://alphapy.readthedocs.io/en/latest/user_guide/pipelines.html#model-object-creation)' - highly customizable setttings for data science pipelines/feature selection. &#x2611;
* '[atm](https://github.com/HDI-Project/ATM)' -  give ATM a classification problem and a dataset as a CSV file, and ATM will build the best model it can. &#x2611;
* '[autogbt](https://github.com/pfnet-research/autogbt-alt)' - an experimental Python package that reimplements AutoGBT using LightGBM and Optuna. &#x2611;
* '[autogluon](https://github.com/awslabs/autogluon)' - AutoGluon: AutoML Toolkit for Deep Learning. &#x2611;
* '[autokaggle](https://github.com/datamllab/autokaggle)' - automated ML system trained using gbdt (regression and classification). &#x2611;
* '[auto-pytorch](https://github.com/automl/Auto-PyTorch)' - automated machine learning with the PyTorch framework. &#x2611;
* '[cvopt](https://github.com/genfifth/cvopt)' - Machine learning parameter search / feature selection module with visualization. &#x2611;
* '[hungabunga](https://github.com/ypeleg/HungaBunga)' - brute-Force all sklearn models with all parameters using .fit .predict &#x2611;
* '[hyperband](https://github.com/thuijskens/scikit-hyperband)' - implements a class HyperbandSearchCV that works exactly as GridSearchCV and RandomizedSearchCV from scikit-learn do, except that it runs the hyperband algorithm under the hood. &#x2611;
* '[hypsklearn](https://github.com/hyperopt/hyperopt-sklearn)' - seems stable - hyperparameter optimization of the data. &#x2611;
* '[scsr](https://github.com/jim-schwoebel/voicebook/blob/master/chapter_4_modeling/train_audioregression.py)' - simple classification / regression (built by Jim from NLX-model). &#x2611;
* **'[tpot](https://epistasislab.github.io/tpot/)'** - TPOT classification / regression (autoML). &#x2611;

## [Metrics](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics)
Various [metrics](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics) are used based on the problem type. 

Here are the standard metrics calculated for every model trained.

### Classification
See the [Classification metrics section](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics) of the user guide for further details.

- accuracy	sklearn.metrics.accuracy_score
- precision	sklearn.metrics.precision_score
- recall	sklearn.metrics.recall_score
- f1	sklearn.metrics.f1_score (pos_label=1)
- f1Micro	sklearn.metrics.f1_score(average='micro')
- f1Macro	sklearn.metrics.f1_score(average='macro')
- rocAuc	sklearn.metrics.roc_auc_score
- rocAucMicro	sklearn.metrics.roc_auc_score(average='micro')
- rocAucMacro	sklearn.metrics.roc_auc_score(average='macro')

### Regression

See the [Regression metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics) section of the user guide for further details.

- max_error metric calculates the maximum residual error.
- Mean absolute error regression loss
- Mean squared error regression loss
- Median absolute error regression loss
- R^2 (coefficient of determination) regression score function.

## Qualtitative observations 

Rank on these axes:
- ease of setup / future support (setup properly) 
- accuracy on most problems (less accurate --> more accurate) 
- speed of modeling process (slow --> fast) 
- documentation quality (poor --> great) 



```diff
- red
+ green
! orange
# gray
```

```
Metrics = https://scikit-learn.org/stable/modules/model_evaluation.html
from sklearn.metrics import classification_report
```

| Modeling script | Ease of setup | Accuracy | Speed | Documentation quality | 
| --------- |  --------- |  --------- | --------- | --------- | 
| alphapy | 4/5|  5/5 | 4/5 | 5/5 | 

['alphapy', 'atm', 'autobazaar', 'autogbt', 'autokaggle', 'autokeras', 'auto-pytorch', 'btb', 'cvopt', 'devol', 'gama', 'hyperband', 'hypsklearn', 'hungabunga', 'imbalance-learn', 'keras', 'ludwig', 'mlblocks', 'neuraxle', 'safe', 'scsr', 'tpot']

## Actively working on (in future)

### üòâ Exploring now
* [metric_learn](https://github.com/scikit-learn-contrib/metric-learn)
* [hyperparameter tuning w/ Ray](https://github.com/ray-project/ray) - tuning hyperparameters 
* '[adanet](https://github.com/tensorflow/adanet)' - Google's AutoML framework in tensorflow (https://github.com/tensorflow/adanet).
* [MLBox](https://github.com/AxeldeRomblay/MLBox) - State-of-the art predictive models for classification and regression (Deep Learning, Stacking, LightGBM,‚Ä¶).
* [SMAC3](https://github.com/automl/SMAC3) - SMAC performs Bayesian Optimization in combination with a aggressive racing mechanism to efficiently decide which of two configuration performs better.
* [Keras-tuner](https://github.com/keras-team/keras-tuner) - Hyperparameter tuning for humans.
* '[gentun](https://github.com/gmontamat/gentun)' - genetic algorithm approach with distributed training capability.
* '[python-sherpa](https://github.com/sherpa-ai/sherpa)' - sherpa bayesian hyperparameter optimization
* [Misvm](https://github.com/garydoranjr/misvm)
* [Tacotron architecture](https://github.com/KinglittleQ/GST-Tacotron) 
* getting into various other ML architectures for keyword spotting, etc.

#### üóúÔ∏è Model compression 
* [PocketFlow](https://github.com/Tencent/PocketFlow) - allow for ludwig model compression.
* '[keras-inference-time-optimizer](https://github.com/ZFTurbo/Keras-inference-time-optimizer) - restructure keras neural network to reduce inference time without reducing accuracy.

### üëé Discarded (due to lack of functionality)

Note these are in the 'archived' folder in case you'd like to expand upon them and use these training back-ends in an expeirmental way.

* '[autobazaar](https://github.com/HDI-Project/AutoBazaar)' - AutoBazaar: An AutoML System from the Machine Learning Bazaar (from the Data to AI Lab at MIT). - this was a bit hard to extract a machine learning model from and the schema was a little hard to make interoperable with Allie; may get to this later if the framework is further supported. 
* '[autokeras](https://autokeras.com/)' - automatic optimization of a neural network using neural architecture search (takes a very long time) - consistently has problems associated with saving and loading models in keras. 
* '[autosklearn](https://github.com/automl/auto-sklearn)' - segmentation faults are common, thus archived. If documentation and community improves, may be good to add back in. 
* '[pLDA](https://github.com/RaviSoji/plda)' - this works only for symmetrical images (as it cannot compute eigenvector for many of the feature arrays we have created). For this reason, it is probably not a good idea to use this as a standard training method. 

### üíª Data modeling notebooks (jupyter)
* Audio file training example
* Text file training example 
* Image file training example
* Video file training example 
* CSV file training example

## Additional documentation
* [Automated Machine Learning tools](https://www.kdnuggets.com/2019/11/github-repo-raider-automated-machine-learning.html)
* [Keras compression](https://github.com/DwangoMediaVillage/keras_compressor)
* [Ludwig](https://uber.github.io/ludwig/examples/#time-series-forecasting)
* [Model compression](https://www.slideshare.net/AnassBensrhirDatasci/deploying-machine-learning-models-to-production)
* [Model compression papers](https://github.com/sun254/awesome-model-compression-and-acceleration)
* [Scikit-small-compression](https://github.com/stewartpark/scikit-small-ensemble)
* [TPOT](https://epistasislab.github.io/tpot/)
* [Voicebook modeling chapter](https://github.com/jim-schwoebel/voicebook/tree/master/chapter_4_modeling)
